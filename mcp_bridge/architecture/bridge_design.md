# MCP Bridge - 智能MCP桥接服务架构设计

## 1. 系统概述

MCP Bridge 是一个智能的 MCP（Model Context Protocol）桥接服务，专为短视频工作流优化设计。它在 Dify 工作流和 CapCutAPI 之间提供高可用的桥接层，支持自动降级、负载均衡和智能路由。

## 2. 部署策略分析

### 2.1 推荐部署方案

**部署位置**: `/home/CapCutAPI-1.1.0`

#### 优势分析
- **Python版本隔离**: Dify使用Python 3.9，CapCutAPI需要Python 3.10+，通过独立虚拟环境避免冲突
- **业务逻辑集中**: 所有剪映相关功能集中在CapCutAPI目录，便于维护
- **资源访问便利**: 直接访问草稿文件和素材，减少跨目录操作
- **服务依赖清晰**: Bridge与MCP Server在同一目录，依赖关系明确

#### 目录结构
```
/home/CapCutAPI-1.1.0/
├── mcp_server.py          # 现有MCP服务器
├── bridge_http.py         # 新增HTTP Bridge
├── venv/                  # Python 3.10+ 虚拟环境
├── requirements.txt       # 依赖管理
└── dfd_*/                # 草稿输出目录
```

### 2.2 Dify工作流集成策略

#### 双重集成路径
1. **主要路径**: Dify原生MCP节点 → MCP Bridge → CapCutAPI
2. **降级路径**: Dify HTTP节点 → CapCutAPI HTTP接口

#### MCP节点配置
- **服务器URL**: `http://127.0.0.1:9101`
- **服务器标识**: `capcut-mcp-bridge`
- **工具映射**: 
  - `create_draft` → 创建剪映草稿
  - `add_video` → 添加视频素材
  - `add_text` → 添加文字素材
  - `save_draft` → 保存草稿文件

## 📋 概述

MCP Bridge是一个智能桥接服务，用于连接Dify MCP系统与CapCut API服务，提供统一的接口管理、自动降级和监控能力。

## 🏗️ 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│                    Dify 工作流系统                           │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   文本生成   │  │   图像生成   │  │   音频合成   │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────┬───────────────────────────────────────┘
                      │ MCP Protocol
┌─────────────────────▼───────────────────────────────────────┐
│                  MCP Bridge 核心层                          │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  路由管理器  │  │  降级控制器  │  │  监控中心    │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  缓存管理器  │  │  重试机制    │  │  健康检查    │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────┬───────────────────────────────────────┘
                      │ HTTP/MCP Dual Protocol
┌─────────────────────▼───────────────────────────────────────┐
│                  目标服务层                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │ CapCut MCP  │  │ CapCut HTTP │  │  其他服务    │         │
│  │   服务器     │  │   插件      │  │             │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
└─────────────────────────────────────────────────────────────┘
```

## 🔧 核心组件

### 1. 路由管理器 (Router Manager)
- **功能**：智能路由请求到最佳服务端点
- **策略**：优先MCP，HTTP降级
- **特性**：动态服务发现、负载均衡

### 2. 降级控制器 (Fallback Controller)
- **功能**：自动检测服务状态并执行降级
- **触发条件**：
  - MCP连接失败
  - 响应超时（>30秒）
  - 错误率超过阈值（>20%）
- **降级策略**：MCP → HTTP → 缓存响应

### 3. 监控中心 (Monitor Center)
- **指标收集**：
  - 请求成功率
  - 响应时间
  - 服务可用性
  - 错误分布
- **告警机制**：实时状态通知

### 4. 缓存管理器 (Cache Manager)
- **策略**：LRU + TTL
- **范围**：API响应、服务状态、配置信息
- **容量**：可配置，默认100MB

### 5. 重试机制 (Retry Engine)
- **策略**：指数退避 + 抖动
- **配置**：最大重试3次，基础延迟1秒
- **智能判断**：区分临时性和永久性错误

## 🔄 工作流程

### 正常流程
1. **请求接收**：Bridge接收Dify MCP请求
2. **路由决策**：选择最佳服务端点（优先MCP）
3. **请求转发**：转发到目标服务
4. **响应处理**：标准化响应格式
5. **结果返回**：返回给Dify工作流

### 降级流程
1. **故障检测**：监控检测到MCP服务异常
2. **降级触发**：自动切换到HTTP模式
3. **协议转换**：MCP请求转换为HTTP请求
4. **服务调用**：调用CapCut HTTP插件
5. **响应转换**：HTTP响应转换为MCP格式

## 🎯 技术架构优化

### 微服务架构设计
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Dify工作流     │    │   MCP Bridge    │    │   CapCutAPI     │
│                 │    │                 │    │                 │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │ MCP节点     │ │───▶│ │ 路由管理器   │ │───▶│ │ 视频处理    │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │ 工作流引擎   │ │    │ │ 熔断器      │ │    │ │ 素材管理    │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
│ ┌─────────────┐ │    │ ┌─────────────┐ │    │ ┌─────────────┐ │
│ │ 任务调度    │ │    │ │ 缓存管理器   │ │    │ │ 草稿导出    │ │
│ └─────────────┘ │    │ └─────────────┘ │    │ └─────────────┘ │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 数据流架构
```
用户请求 ──▶ Dify工作流 ──▶ MCP Bridge ──▶ CapCutAPI
    ▲                           │              │
    │                           ▼              ▼
    └── 响应结果 ◀── 结果聚合 ◀── 缓存层 ◀── 视频处理
                      │
                      ▼
                  监控指标 ──▶ Prometheus ──▶ Grafana
```

### 容错机制设计
```
┌─────────────────────────────────────────────────────────────┐
│                    容错机制层次                              │
├─────────────────────────────────────────────────────────────┤
│ L1: 请求级容错                                              │
│     ├── 超时控制 (5s/15s/30s)                              │
│     ├── 重试机制 (指数退避)                                 │
│     └── 请求去重                                           │
├─────────────────────────────────────────────────────────────┤
│ L2: 服务级容错                                              │
│     ├── 熔断器 (失败率阈值)                                 │
│     ├── 限流器 (令牌桶算法)                                 │
│     └── 负载均衡 (健康检查)                                 │
├─────────────────────────────────────────────────────────────┤
│ L3: 系统级容错                                              │
│     ├── 降级策略 (缓存/简化处理)                            │
│     ├── 资源隔离 (CPU/内存限制)                             │
│     └── 优雅关闭 (请求排空)                                 │
└─────────────────────────────────────────────────────────────┘
```

## 📊 接口规范

### MCP接口
```json
{
  "jsonrpc": "2.0",
  "method": "tools/call",
  "params": {
    "name": "capcut_create_draft",
    "arguments": {
      "video_url": "string",
      "draft_name": "string",
      "description": "string"
    }
  },
  "id": 1
}
```

### HTTP接口
```json
{
  "endpoint": "/api/draft/create",
  "method": "POST",
  "body": {
    "video_url": "string",
    "draft_name": "string", 
    "description": "string"
  }
}
```

## 🛡️ 容错设计

### 1. 多层降级
- **L1**: MCP主服务
- **L2**: HTTP备用服务  
- **L3**: 缓存响应
- **L4**: 默认响应

### 2. 熔断机制
- **开启条件**：错误率>50%，持续>60秒
- **恢复策略**：半开状态探测
- **保护范围**：单个服务端点

### 3. 超时控制
- **连接超时**：5秒
- **读取超时**：30秒
- **总体超时**：60秒

## 📈 性能优化

### 1. 连接池
- **MCP连接**：长连接复用
- **HTTP连接**：连接池管理
- **并发控制**：最大100并发

### 2. 异步处理
- **非阻塞IO**：asyncio架构
- **批量处理**：支持批量请求
- **流式响应**：大文件流式传输

### 3. 智能缓存
- **热点数据**：自动识别并缓存
- **预加载**：预测性数据加载
- **压缩存储**：减少内存占用

## 🔧 配置管理

### 环境配置
```yaml
# MCP Bridge 配置
mcp_bridge:
  # 服务配置
  host: "0.0.0.0"
  port: 8080
  
  # MCP服务配置
  mcp_services:
    capcut:
      url: "mcp://localhost:9002"
      timeout: 30
      retry_count: 3
  
  # HTTP服务配置  
  http_services:
    capcut_plugin:
      url: "http://localhost:9001"
      timeout: 30
      retry_count: 3
  
  # 降级配置
  fallback:
    enabled: true
    error_threshold: 0.2
    timeout_threshold: 30
    
  # 缓存配置
  cache:
    enabled: true
    ttl: 300
    max_size: 100
```

## 🚀 部署架构

### 开发环境
```
Dify (8000) ←→ MCP Bridge (8080) ←→ CapCut Plugin (9001)
```

### 生产环境
```
Load Balancer
    ↓
Dify Cluster ←→ MCP Bridge Cluster ←→ CapCut Service Cluster
    ↓                ↓                      ↓
  Redis          Monitoring            Health Check
```

## 📋 实施计划

### 阶段1：核心功能（1-2天）
- [x] 基础架构搭建
- [ ] 路由管理器实现
- [ ] 基础MCP/HTTP转换

### 阶段2：高级特性（2-3天）
- [ ] 降级控制器
- [ ] 监控系统
- [ ] 缓存管理

### 阶段3：优化完善（1-2天）
- [ ] 性能优化
- [ ] 测试验证
- [ ] 文档完善

## 🎯 预期收益

### 可靠性提升
- **服务可用性**：99.9% → 99.99%
- **故障恢复时间**：手动30分钟 → 自动30秒
- **错误率降低**：50%以上

### 性能优化
- **响应时间**：平均减少30%
- **并发能力**：提升3倍
- **资源利用率**：提升40%

### 运维效率
- **监控覆盖**：100%关键指标
- **自动化程度**：90%以上
- **故障定位时间**：减少80%

---

**设计原则**：高可用、高性能、易维护、可扩展
**技术栈**：Python 3.11+、asyncio、FastAPI、Redis
**更新时间**：2025年1月14日